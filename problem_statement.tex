\section{Repairs}\label{s:problem}
This section presents the problem setting and definitions.  

\subsection{Conditional Assignments}
\sys generates cleaning pipelines that are composed of conditional assignments, which conditionally assign value $v$ to attribute $r[attr]$ if predicate $pred$ evaluates to true:
{\small\begin{verbatim}
    ca(r):
      if pred(r): r[attr] = v 
      return r
\end{verbatim}
}
\noindent A conditional assignment can evaluate over relation $R$ by evaluating over each record in the relation:  $ca(R) = \{ca(r) | r \in R\}$.   Note that conditional assignments can be coarse or fine-grained depending on the specificity of the predicate.  

\begin{example}\it
  \texttt{ca(code.prefix(``NY''), code, ``NYC'')} sets the code to ``NYC'' for all records where the city code starts with ``NY''.  This single condition could be replaced with three operations with predicates  \texttt{id=2}, \texttt{id=3}, \texttt{id=4} {\it for the example table}, where operation can be executed and added to a cleaning pipeline independently. Our experiments highlight the role that different granularities play in the runtime and quality of the search results.
 \end{example}

% The size of the search space can be controlled by how coarse- or fine-grained these repair functions are.  For example, one could wrap the entire results of \texttt{ispell(rec)} into a single function or break it up into each modification per distinct value.  The result is that $x_i$ is a set of each such repair, and over the entire library and different parameter settings, we can generate a set $X$ of all repairs possible.

A cleaning pipeline is a composition of conditional assignment operations, where $(ca_2 \circ ca_1)(r) = ca_2(ca_1(r))$. Note that $ca_1$'s changes may be overwritten by $ca_2$.  A composition can similarly be evaluated over a relation $R$: $(ca_2\circ ca_1)(R) = ca_2(ca_1(R))$.    Given a set of conditional assignments $\mathcal{C}$, the set of all compositions from $\mathcal{C}$ defines the plan space $\mathcal{P}$.   Next, we will discuss how the set of conditional assignments $\mathcal{C}$ is generated.


  % For convenience, let library $L=\{\}$let $l_{i,k} = o_i(\phi_k, R)$ denote a parameterized version of $o_i$, and library $L = \{l_{i,j}, \cdots \}$ be the set of all possible parameterized operators.

% L = \{\texttt{l}_1,...,\texttt{l}_N\}$ of data cleaning operators that are specialized cleaning systems or functions that will be used to build a cleaning pipeline. Each operator takes in parameters $\phi_i$ from an overall (continuous or discrete) set of parameters $\Phi_i$:

% We could further have a \texttt{edit\_matcher(thresh, attr)}, which applies searches for pairs of values within a certain edit distance and merges them to the most frequent value (as with the previous method the parameter space is the threshold in $\mathbb{N}$).
%We could also have a functional dependency resolver \texttt{fd\_resolve(fd)}, which enforces the specified functional dependency with a chase algorithm (the parameter space is the choice  $\{ \texttt{city\_name} \rightarrow \texttt{city\_code}, \texttt{city\_code} \rightarrow \texttt{city\_name}\}$).
% Users define the library and the set of allowable parameters for each method.

%\vspace{0.5em}\noindent\textbf{Method API: } Each method in the library must implement a function that applies itself to a relation $r$ and returns the results of its cleaning $x_i$:
%\[
%x_i = \texttt{l}_i.\texttt{generate(r)}
%\]



\section{Quality Functions}

A quality function measures a specific notion of cleanliness for a relation, and is used as the cost model for the pipeline search.  The predominant way that quality functions are defined is in terms of SQL aggregation queries. For example, the number of functional dependency violations (e.g., $\texttt{city\_name} \rightarrow \texttt{city\_code}$) is expressible as:
{\small\begin{lstlisting}
  q1(T): SELECT count(1)
         FROM T as c1, T as c2,
         WHERE (c1.city_name == c2.city_name) AND
               (c1.city_code <> c2.city_code)
\end{lstlisting}}
\noindent Conditional functional dependency violations is a well-studied quality function, and many systems optimize for this class of objectives~\cite{rekatsinas2017holoclean,DBLP:conf/sigmod/ChuIKW16}.   

However, this example highlights that \emph{even seemingly simple data cleaning problems can require the flexibility to express multiple quality functions.}   For example, record 1 does not violate the above functional dependency, and will be missed by most functional dependency solvers.  Suppose the analyst observed a histogram of city names and noted that there were a large number of singleton entries. Thus, she could write a second quality function that counts the number of singleton entries.  This is an example of a quality measure that other systems such as Holoclean and Holistic Data Cleaning do not support as input~\cite{rekatsinas2017holoclean,DBLP:conf/sigmod/ChuIKW16}:
{\small
\begin{lstlisting}
  q2(T): SELECT count(1)
         FROM ( SELECT count(1) as cnt FROM T,
                GROUP BY city_name HAVING cnt = 1)
\end{lstlisting}}
Finally, the user can embed the downstream application as a user defined function (UDF).  For instance, the machine learning model accuracy can be added as a quality function that calls a UDF \texttt{model.eval()}.  In our experiments using the London Air Quality benchmark, we show how a parametric auto-regressive model that measures curve smoothness can be expressed as a quality function:
{\small\begin{lstlisting}
  q3(T): SELECT avg(err) AS acc
         FROM ( SELECT model.eval(X) = Y FROM T )
\end{lstlisting}}
\noindent \sys lets the user compose linear combinations of quality functions together. We model the composition over $n$ individual quality functions as $Q(T) = \sum_{i=1}^n w_iq_i(T)$.  For example, $n=2$ in the example, and captures the semantic functional dependency issues as well as the syntactic string splitting errors in a single cost model.  Our experiments simply set $w_i=\frac{1}{n}$.

We designed the quality function in this way for several reasons.  SQL aggregations can be incrementally computed and maintained, and can be efficiently approximated.  This is important because each conditional assignment typically modifies a small set of records, and thus allows efficient re-computation that scales to the number of cleaned records rather than the size of the dataset.  The linear compositions enables parallelization across each $q_i$ term, and the aggregation functions are typically algebraic functions that can be parallelized across data partitions.  The combination of incremental maintenance, and data and quality function parallelization speeds up evaluation by up to 20x in our experiments.

% Without loss of generality, let $Q(R)$ be a quality function which maps from the set of all possible instances $Q(R): \mathcal{R} \mapsto [0,1]$ be a quality function where $0$ implies that the instance $R$ is clean, and a higher value correspond to a dirtier table.
% Since running a plan $p$ on the initial dirty table $R_{dirty}$ returns another table, $Q(p(R_{dirty}))$ is able to return a quality score for any pipeline in the plan space.



\iffalse
\subsection{Problem Statement}
We now present the search problem to clean cell-inconsistencies:
\begin{problem}[Search Problem]%[$\textsf{clean}(Q,R_{dirty},L)$]
Given quality function $Q$, Library $L$, relation $R_{dirty}$, find valid plan $p^* \in \mathcal{P}$ that optimizes $Q$:
\[
p^* = ~ \argmin_{p \in P} Q( p(R_{dirty}) ).  
\]
\end{problem}
$p^*(R_{dirty})$ returns the cleaned table, and $p^*$ can potentially be applied to any table that is union compatible with $R_{dirty}$.  A desirable property of this problem formulation is that it directly trades off runtime with cleaning accuracy and can be stopped at any time (though the cleaning program may be suboptimal).

This problem is challenging because the set of all parameterized cleaning operators can be too large to materialize, and the set of possible conditional assignments is potentially unbounded.  We  rely on properties of the quality function to quickly assess the quality of candidate pipelines in parallel. The next sections describe our system architecture and optimizations to efficiently search the plan space.
\fi

% To limit the search space, we assume predicates are of the form $attr = v$ where $v$ is a value found in the relation.  We also
%  At the limit, \sys simply explores $P$ and identifies the optimal plan.


