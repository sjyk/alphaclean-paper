\section{Architecture and API}
Now, we will overview some of the preliminary concepts and describe how this formalism inspires a modular system API.

\begin{figure}[t]
% \vspace{-5pt}
\centering
 \includegraphics[width=\columnwidth]{figures/alphacleanarch.png}
 \caption{ \sys is given a specification of quality (e.g., integrity constraints or a statistical model the data must conform to) and a language  of  allowed  data  transformations,  and  it  searches  to find a sequence of transformations that maximizes the quality metric. \label{fig:arch} }
\end{figure}


\subsection{Overview}
\sys is designed as a software stack with three layers: a specification layer, a search layer, and an execution layer.
To understand how these layers interact, let us reconsider the example in Section 2.
\begin{table}[ht!]
\centering
\label{my-label}
\begin{tabular}{|l|l|l|}
\hline
\rowcolor[HTML]{000000} 
& {\color[HTML]{FFFFFF} city\_name}            & {\color[HTML]{FFFFFF} city\_code}   \\ \hline
1 & San Francisco                                & SF                                  \\ \hline
2& {\color[HTML]{FE0000} \textbf{New York}}     & NY                                  \\ \hline
3 & New York City                                & {\color[HTML]{FE0000} \textbf{NYC}} \\ \hline
4 & {\color[HTML]{FE0000} \textbf{San Francisc}} & SF                                  \\ \hline
5 & San Jose                                     & SJ                                  \\ \hline
6 & San Mateo                                    & SM                                  \\ \hline
7 & New York City                                & NY                                  \\ \hline
\end{tabular}
\end{table}


\subsubsection{Specification Layer} The provides an API for specifying a quality function and a language of transformations. The language is generated through a transformation templates which are dynamically populated by literals in the database.
A template is a parametrized transformation:
\[T(R, [\theta_1, \theta_2,...,\theta_k] ): \mathcal{R} \mapsto  \mathcal{R},\] where the parameters $[\theta_i]$ are populated by literal values.
The users annotates the the type of the parameter (attribute, value, predicate, token), and the system dynamically generates all possible literal instances of this transformation.
In the running example, consider the following function:
\[
\textsf{find\_replace}(\text{source}, \text{target}, \text{attribute})
\]

Additionally, \sys can apply machine learning techniques to prune search branches.
To do this, all the transformations in the language have to be featurized to a $d$ dimensional vector:
\[
\textsf{feat}(T) \mapsto \mathbb{R}^d
\]
\sys trains a classifier that maps the d-dimensional vector to $0$ (keep) or $1$ (prune).
This allows the search to execute much faster on future data (or future blocks).
The specification layer provides some default featurization schemes which can be customized.

\subsubsection{Search Layer} The next layer is the search layer, which implements the basic search algorithm of \sys. This algorithm is a distributed best-first greedy search.  
With no additional information, the search approach described would have to evaluate $61^3 = 226981$ transformations, which is clearly impractical even for this small example.
This layer also provides an interface for custom search optimizations:

\vspace{0.5em}\noindent\textbf{Static Optimizations: } A static optimization is a regular expression that all transformation sequences must satisfy independent of the data. 
\[\textsf{static\_opt}(L, \text{regex} ) \mapsto L'\]
For example, since the find-and-replace operations are idempotent, i.e., $T(T(R)) = T(R)$, we may want to only consider the set of all sequences with no neighboring repeated transformations. Similarly, we may also want to prune all search branches that make no effect (i.e., find-and-replace New York with New York).
These two regular expressions alone reduce the overall number of evaluations by $48\%$ in the above example (120050 v.s. 226981 evaluations).
There are several other possible optimizations  such as avoiding changes that reverse previous changes $T_i(T_j(R)) = R$.


\vspace{0.5em}\noindent\textbf{Dynamic Optimizations: } A dynamic optimization can query the data and cost function to generate rules that are instance-specific:
\[\textsf{dyn\_opt}(Q, R, L) \mapsto \text{regex}\]
For example, we may want to ensure that all the evaluations are ``correlated'' with the cost function--that is it makes modifications that are likely to affect the costs.
This is possible if the cost separable where we have a score for each cell. In this case, we can find all the cells in violation of the functional dependencies and make sure that the ``source'' field of the find-and-replace operations only match values that are in violation.
These optimizations are called ``dynamic' because they can be determined from the active domain (i.e., after applying a transformation, recalculate new optimization rules).
Applying this optimization (in addition to the others) to the example reduces the search space to 1582 evaluations v.s. 226981 unoptimized (143x reduction).

\vspace{0.5em}\noindent\textbf{Blocking Rules: }  Arbitrary constraint satisfaction problems are challenging because all variables can interact. While this is certainly the case for arbitrary quality functions, in many cases, data errors are localized. For example, replacing \texttt{San Francisc} with \texttt{San Francisco} has no effect on the records referring to \texttt{New York City}. The final class of optimizations are blocking rules which have been widely used in entity resolution systems:
\[\textsf{block}(Q, R, L) \mapsto \{R_1,...,R_k\} \]
For quality functions generated from dependencies, we can determine blocks analytically--looking at which violating tuples are linked through the constraint.
However, in general, these blocking rules can be learned (e.g., with clustering) or user defined.
The search can execute on each of the blocks independently.


\vspace{0.5em}\noindent\textbf{Learned Optimizations: } 
As an example, consider the sequence of transformations described in the example:
\begin{lstlisting}
find_replace(New York, New York City, city_name)
find_replace(San Francisc, San Francisco, city_name)
find_replace(NYC, NY, city_code)
\end{lstlisting}
One observation is that the source and target strings in the optimal sequence are very close in terms of string similarity (as opposed to arbitrary transformations).
If each of these operations was featurized with a single scalar that is the edit-distance between the two strings, then the classifier could learn a pruning threshold (i.e., not considering find-and-replace operations above that threshold).

\subsubsection{Execution Layer} Finally, once the sequence of transformations are found with the search, the program is ready to execute. \sys provides an API to optimize the transformation sequence (merging transformations that can be executed in the same iterative loop) and replacing literal values when possible. 
For example, consider these operations:
\begin{lstlisting}
find_replace(New York, New York City, city_name)
find_replace(None, San Francisco, city_name)
find_replace(NYC, NY, city_code)
\end{lstlisting}
Since they do not conflict, it would be inefficient to execute them sequentially and iterate over the data three separate times.
Instead, one should combine the operations together and execute at once:
\begin{lstlisting}
for r in rows:
 switch r[city_name]
    case New York: r[city_name] = New York City
    case None: r[city_name] = San Francisco
    default: pass
    
 switch r[city_code]
    case NYC: r[city_code] = NY
    default: pass
\end{lstlisting}

