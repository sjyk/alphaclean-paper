Modern datasets can exhibit many different types of data errors, and users often are not aware of them up front.  Instead, users incrementally identify data quality issues throughout the data cleaning process. Thus, data cleaning is a human-in-the-loop process, and systems should be optimized so the user can rapidly specify, refine, and assess her notion of data quality in order to reach a sufficient level of cleanliness for her needs.   However, this goal is at tension with existing approaches to data cleaning, which develop systems specialized to particular classes of data errors (e.g., statistical outliers, constraint violations, value errors).  Unfortunately, users must pick and ``glue'' different systems together, which can be very challenging.

We present a system called \sys to explore the potential of a generic tree-search algorithm that lets users specify arbitrary data-quality measures as optimization criteria, and generates understandable sequences of user-specified data transformation operators that maximize the quality measure.  This flexible interface can express different types and combinations of data errors.  Our hypothesis is that data cleaning problems are highly structured, and a learning-based approach that can identify these structures for different cleaning problems.  We evaluate the trade-offs of this generic approach using a synthetic multi-error dataset, and find \ewu{XXX}.  On \ewu{N} standard data cleaning benchmarks, we find that the runtime and cleaning accuracy are comparable with recently reported results.


% Managing a pipeline composed of many disparate systems is sufficiently difficult to maintain, debug, and interpret, that many data users opt to write custom scripts instead.  Rather than focus on a specific class of errors, we propose to view all data cleaning problems within a single unified abstraction: sequential search over a language of allowable data transformations to maximize an objective function that encodes a notion of ``cleanliness''.  This general problem is often intractable in the worst case, but recent AI successes such as Google's AlphaGo have shown that a combination of machine learning and parallelized search can solve planning problems previously considered impractical.  We present \sys, a general data cleaning systems which borrows these insights to support arbitrary combinations of existing and new data errors.  We evaluated \sys against special purpose systems over 8 different datasets.  When there is a single error type, \sys matches or exceeds the accuracy of special purpose approaches and is camparable in runtime.  On multi-error datasets, \sys has 10\% higher accuracy than a naive combination of specialized systems and runs over $2\times$ faster.  Finally, our optimizations can reduce the basic search algorithm from exponential to linear runtime.
