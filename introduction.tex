\section{Introduction}\label{intro}\sloppy
Data cleaning is widely recognized as a major challenge in almost all forms of data analytics~\cite{nytimes}, and an analyst may spend upwards of 80\% of her time to clean and prepare the data. 
\emph{Cell inconsistencies} are an important class of data errors where record values are missing, incorrect, contain inconsistent references to the same entities, or contain artifacts from the extraction process.  
Improperly handled errors can affect the performance and accuracy of downstream applications such as reports, visualizations, and machine learning models.
In response, the research community has developed increasingly sophisticated methods for detecting and automatically repairing errors in large datasets~\cite{dc, rekatsinas2017holoclean, DBLP:journals/pvldb/KrishnanWWFG16, DBLP:conf/sigmod/ChuIKW16, mudgal2018deep, doan2018toward}.
The burden on the analyst is gradually shifting away from the design of hand-written data cleaning scripts, to building and tuning complex pipelines of automated data cleaning libraries.

Even so, designing reliable and accurate cleaning pipelines can be very challenging~\cite{krishnan2016hilda}.
Despite all of these components being under the umbrella of ``data cleaning'', there is no unified way to specify a global objective or reason about interactions between components; each has its own abstractions, parameter space, and guarantees (or lack thereof).
For example, constraint-resolution systems use integrity constraints to specify objectives~\cite{rekatsinas2017holoclean,DBLP:conf/sigmod/ChuIKW16}, while numerical outlier detection techniques use thresholds~\cite{bailis2016macrobase}.
In query optimization jargon, there is no objective definition of a \emph{plan space} (set of ways to compose and tune a pipeline of data cleaning operations) and \emph{cost model} (a way of evaluating the value of a pipeline).

This paper proposes a framework, called \sys, to facilitate holistic optimization of data cleaning pipelines.
A key insight is that a large portion of data repairs can be described as a compositions of value-replacement functions, i.e., if a record satisfies a predicate replace a specified attribute with a target value.
Rather than treating each pipeline component as a black-box transformation of an entire table, \sys extracts the constituent replacements.
Given a library of data cleaning methods, each suggests potential replacements policies which are aggregated into a central set.
This defines a well-posed plan-space, namely, the set of all compositions of candidate functions.
This plan space captures method reordering, method exclusion, and applying a method to a subset of records.

Unlike in the analogy to query optimization, this cost model in data cleaning more ambiguous---cleanliness is in the eyes of the beholder. Data quality issues are often identified as part of developing an application and interacting with the data~\cite{krishnan2016hilda}.  
Data scientists have an evolving definition of what quality measures are important.
Therefore, we need an extensible cost model that can be quickly modified by an end-user.
To this end, \sys evaluates plan quality with a summation of user-specified SQL aggregates.  We further provide a library that translates common classes of data errors such as denial constraint violations, numerical outliers, and other statistical inconsistencies into relational algebra.
This model is general enough that it can describe a large variety of data quality measures, and be efficient to incrementally evaluate when possible, e.g., with fast incremental view maintenance techniques~\cite{DBLP:journals/vldb/KochAKNNLS14,krishnan2015svc}.   

The immensely large plan space (branching factors in the millions in our experiments) and the lack of \emph{a priori} knowledge of the cost model, presents an enormous technical challenge.
We borrow recent ideas from AI, where search heuristics are learned from data.
We treat pipeline generation and tuning as a greedy tree-search problem.   Each path is a candidate data cleaning pipeline whose quality can be evaluated by running the pipeline over the input dataset and running the quality function.  The benefit is that the search can be easily parallelized across candidate paths as well as partitions of the dataset.  To accelerate the search process and prune unpromising paths, we dynamically learn a model that predicts the expected quality of a given cleaning pipeline.  This model thus avoids the need to execute the pipeline and quality function in order to evaluate a given path.  We use periodic synchronization to update the prediction model across parallel searches and merge transformations that touch disjoint sets of data.


\noindent To summarize our contributions:

\begin{itemize}[leftmargin=*, topsep=0mm, itemsep=0mm]
  \item A framework, \sys, which allows for extensible generation of a data cleaning plan space from existing cleaning methods and an flexible API for defining custom quality measures to search the space.
  \item A progressive search algorithm that quickly generates acceptable cleaning pipelines, adaptively prunes the search space, and a suite of pragmatic optimizations including multi-node parallelization and data sharing to reduce network communication bottlenecks that reduce runtimes by \ewu{XXX$\times$}.   
  \item A systematic study of the benefits and limitations of \sys in terms of data cleaning accuracy (precision, recall), and the runtime.  We show that \sys can solve incremental refinements of the data quality measure $yyy\times$ faster than from scratch, and that \ewu{SOME OTHER FINDING}
\end{itemize}



