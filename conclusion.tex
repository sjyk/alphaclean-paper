\section{Conclusion and Future Work}
We have shown that automated data cleaning for predictive models can be cast in a statistical boosting framework.  We have prototyped this idea in \sys, a new data cleaning system that detects errors in ML data and uses knowledge of the labels to adaptively select from a set of repair actions to maximize prediction accuracy.
Our evaluation on a collection of 12 datasets from Kaggle, the UCI repository, real-world data analyses, and production datasets that show that \sys can increase absolute prediction accuracy by up to 9\% over the best non-ensembled alternatives. In addition, we evaluated \sys on production datasets from a data science company and showed that, despite high class imbalances in both datasets, \sys can automatically detect data errors and improve the AUC of the prediction model by $8-9\%$.  We also demonstrate how our optimizations can achieve an end-to-end speed up of over $22\times$

%can parallelize the inner-loop of the boosting operation, and on a 16-core machine \sys achieves a 9.7x speedup. Similarly, we show that building an inverted index can speed up operator selection time by 2.3x.

We are excited about these promising results and have identified a number of future research directions to improve the practicality of the system.  The first is to relax the current requirements of having a test set with clean labels.   Although it may be difficult to acquire sufficient test labels, data science application often have access to an indirect model accuracy measure.  For instance, user retention may be strongly correlated to model accuracy and much easier to obtain.  This will likely require a more complex ensembling technique than boosting.  A second direction is to support parameterized cleaning operations, such as regular expression extractors, for which the number of possible parameter values is unbounded.  We believe that recursive discretization procedures are a promising approach.  A third direction are further performance optimizations so that \sys can scale to large and heterogeneous settings such as data lakes.  Finally, we are actively seeking to continue industrial collaborations and real-world evaluations of our system.  The system and code is open source and can be accessed at {\bf anonymized for submission.}
