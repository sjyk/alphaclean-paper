\section{Conclusion and Future Work}
The research community has developed increasingly sophisticated data cleaning methods~\cite{dc, rekatsinas2017holoclean, DBLP:journals/pvldb/KrishnanWWFG16, DBLP:conf/sigmod/ChuIKW16, mudgal2018deep, doan2018toward}.
The burden on the analyst is gradually shifting away from the design of hand-written data cleaning scripts, to building and tuning complex pipelines of automated data cleaning libraries.
The main insight of this paper is that tuning pipelines of data cleaning operations is very different than tuning pipelines for machine learning.

Rather than treat each pipeline component as a black-box transformation of the relation, \sys canonicalizes their {\it  repairs} as conditional assignment operations.   Given a library of  cleaning operators, their outputs contribute to a pool of conditional assignments. This defines a well-posed search space, namely, the set of all pipelines composed of conditional assignments.  % This space models reordering, exclusion, and applying a method to a subset of records.
  
Although our results suggest that leveraging advances in planning and optimization can solve a range of data cleaning benchmarks, they are counter-intuitive because of greedy nature of the system and its enormous search space.  This raises a number of questions about future opportunities in data cleaning.  Why does a greedy search achieve strong results on widely-used cleaning benchmarks? Are the benchmarks too simple or are cleaning problems simply highly structured?  We hope to understand the fundamental reasons for when and why search-based approaches should perform well.

In addition, we are excited to extend \sys towards a more flexible, visual, and interactive cleaning process.  We plan to integrate \sys with a data visualization system~\cite{Wu2017CombiningDA} so users can visually manipulate data visualizations that are translated into quality functions.  This will also require work to characterize failure modes and provide high-level tools to debug such cases.  



% The prevailing wisdom in the design of data cleaning algorithms is to exploit the details of specific problem rather than considering the most general cases, and our experiments suggest that this a general framework like \sys can achieve parity in terms of accuracy.
% While the serial implementation of \sys can be much slower than the competitor specialized frameworks, \sys can be efficiently distributed to significantly reduce the gap.
% 
% These results should be considered a proof-of-concept that such a data cleaning \sys can be built around the recent results in AI. 
% However, to us, these results are still counter-intuitive, and raise a number of speculative questions for the future: (1) are specialized systems overly engineered for worst-case guarantees and perhaps real-datasets are not that pathalogical, (2) maybe the benchmarks that we consider in data cleaning are too easy to brute-force, (3) what are the failure modes and corner cases of \sys in real data.
% We hope to consider these problems in future work, as well as extending the system to novel settings.
% In particular, we are interested in \sys as a middleware layer for data visualization.
% A user can manipulate data in a visual UI and these manipulations can be translated into a quality function.
% 
