\section{Machine Learning for Pruning}
To effectively search through the language of transformations, search heuristics are important.
However, it can be challenge to devise these heuristics \emph{a priori}.
This section describes how Machine Learning can be used to learn a search heuristic as data is cleaned.

\subsection{Motivation}
The search algorithms in  most automatic data cleaning frameworks are carefully tuned for a specific quality function or class of quality functions. For example, the chase used in functional dependency resolution does not make an edit to the table unless it enforces at least one tuple's FD relationship. Exploiting the structure of the specific problems allows for a tractable solution technique. Similarly, in entity matching problems, one restricts the search to only matching tuples that are likely to be similar based on some similarity metric.
These are not static optimizations, i.e., knowing how to prune the search space requires knowing the underlying data or making strong modeling assumptions about the types of transformations used.

\subsection{Featurized Transformations}
Suppose we made only the following assumption about the language of transformations used.
Each transformation consists is described by a fixed-length feature vector in $\mathbb{R}^k$:
\[
\textsf{feat}: T \mapsto \mathbb{R}^k 
\]
An example of a featurization, consider a transformation from the the running example:
\begin{lstlisting}
find_replace(New York, New York City, city_name)
\end{lstlisting}
The featurization could encode the string similarity of the two literal parameters and an indicator vector describing which column it applies to.

Consider an alternative to a predefined search heuristic where we clean data in small blocks.
For the initial blocks, we search without a heuristic.
As we continuously perform the search, we train a classifier on these features to reject search branches that are not typically in the final solution.
This allows us to exploit any patterns in the literal parameters that repeatedly occur.

For example, some columns might not be dirty and are not worthwile to clean.
In the example above, another observation could be that the source and target strings in the optimal sequence are very close in terms of string similarity (as opposed to arbitrary transformations).
If each of these operations was featurized with a single scalar that is the edit-distance between the two strings, then the classifier could learn a pruning threshold (i.e., not considering find-and-replace operations above that threshold).

\subsection{Learning to Prune}
\sys executes the search on each block of data.
The result is a sequence of transformations to optimize the quality metric on that block.
Every transformation in this sequence can be treated as a positive training example $L^+$, and every transformation not in this sequence can be treated as a negative example $L^-$.
The idea is that if we apply the search to a sufficient number of blocks then we can train a classifier to predict whether a transformation will be included in the final sequence.
It is important to note that this prediction is over the transformations and not the data. 

Internally, \sys uses a Logistic Regression classifier to make this classification. The Logistic Regression is tuned towards False Positives (i.e., keep a bad search branch). This is done by training the model and shifting the prediction threshold until there are no False Negatives. 

